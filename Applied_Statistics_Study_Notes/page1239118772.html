<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- 4.12.2 -->
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <link rel="stylesheet" href="combined.css"/>
    <script src="split/split.min.js"></script>
    <link rel="stylesheet" href="inline_styles.css"/>
    <style type="text/css">
        /* <![CDATA[ */
            
        /* ]]> */
    </style>
</head>
<body>

<div class="full-height-container">
<div id="sidebar" class="split">
<div class="navgroup" id="search">
<form action="search.html" class="aui">
<input type="text" name="q" id="tipue_search_input" class="medium-field text">
<input class="button submit" type="submit" value="Search"></form>
</div>
<div class="navgroup" id="navigation">
<ul><li><span>Applied Statistics Study Notes</span></li></ul>
</div>
</div>
<div id="content" class="split">
<div class='wiki-page'>
<div class='wiki-title'>
<h1 class='page-title-lvl-cover' id='Bookmark1'>Applied Statistics Study Notes</h1>
</div>
<div class='wiki-content'>
<div class="contentLayout2">
<div class="columnLayout two-equal" data-layout="two-equal">
<div class="cell normal" data-type="normal">
<div class="innerCell">
<p><!--inline_style_1--></p><div class="toc-macro rbtoc1589399779078">
<ul class="toc-indentation">
<li><a href="#Bookmark2" title="1. Statistics Fundamentals">1. Statistics Fundamentals</a>
<ul class="toc-indentation">
<li><a href="#Bookmark3" title="1.1. Descriptive Statistics">1.1. Descriptive Statistics</a></li>
<li><a href="#Bookmark4" title="1.2. Law of Large Numbers (LLN)">1.2. Law of Large Numbers (LLN)</a></li>
<li><a href="#Bookmark5" title="1.3. Central Limit Theorem (CLT)">1.3. Central Limit Theorem (CLT)</a></li>
<li><a href="#Bookmark6" title="1.4. Matrix Determinant ">1.4. Matrix Determinant </a>
<ul class="toc-indentation">
<li><a href="#Bookmark7" title="1.4.1. 3x3 matrix">1.4.1. 3x3 matrix</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#Bookmark8" title="2. Hypothesis Testing">2. Hypothesis Testing</a>
<ul class="toc-indentation">
<li><a href="#Bookmark9" title="2.1. Terms">2.1. Terms</a></li>
<li><a href="#Bookmark10" title="2.2. Power in significance test:">2.2. Power in significance test:</a></li>
<li><a href="#Bookmark11" title="2.3. Sample Size">2.3. Sample Size</a>
<ul class="toc-indentation">
<li><a href="#Bookmark12" title="2.3.1. Estimating a mean">2.3.1. Estimating a mean</a></li>
<li><a href="#Bookmark13" title="2.3.2. Estimating a proportion for a large population">2.3.2. Estimating a proportion for a large population</a></li>
<li><a href="#Bookmark14" title="2.3.3. Estimating a proportion for a small population (N is small)">2.3.3. Estimating a proportion for a small population (N is small)</a></li>
</ul>
</li>
<li><a href="#Bookmark15" title="2.4. Steps">2.4. Steps</a></li>
<li><a href="#Bookmark16" title="2.5. Types">2.5. Types</a>
<ul class="toc-indentation">
<li><a href="#Bookmark17" title="2.5.1. Test on a population proportion">2.5.1. Test on a population proportion</a></li>
<li><a href="#Bookmark18" title="2.5.2. Test on a population mean">2.5.2. Test on a population mean</a></li>
<li><a href="#Bookmark19" title="2.5.3. Test on two sample proportions">2.5.3. Test on two sample proportions</a></li>
<li><a href="#Bookmark20" title="2.5.4. Test on paired means">2.5.4. Test on paired means</a></li>
<li><a href="#Bookmark21" title="2.5.5. Test on two independent sample means">2.5.5. Test on two independent sample means</a></li>
<li><a href="#Bookmark22" title="2.5.6. Test on the distribution of categorical data: Chi-squared test &chi;2 ">2.5.6. Test on the distribution of categorical data: Chi-squared test &chi;2 </a></li>
<li><a href="#Bookmark23" title="2.5.7. Test on one variance: Chi-squared test &chi;2 ">2.5.7. Test on one variance: Chi-squared test &chi;2 </a></li>
<li><a href="#Bookmark24" title="2.5.8. Test on two variance: F-test">2.5.8. Test on two variance: F-test</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#Bookmark25" title="3. ANOVA">3. ANOVA</a>
<ul class="toc-indentation">
<li><a href="#Bookmark26" title="3.1. Assumptions">3.1. Assumptions</a></li>
<li><a href="#Bookmark27" title="3.2. ANOVA Table">3.2. ANOVA Table</a></li>
</ul>
</li>
<li><a href="#Bookmark28" title="4. Linear Models">4. Linear Models</a>
<ul class="toc-indentation">
<li><a href="#Bookmark29" title="4.1. Assumptions (LINE):">4.1. Assumptions (LINE):</a></li>
<li><a href="#Bookmark30" title="4.2. Least-Squares Linear Regression">4.2. Least-Squares Linear Regression</a></li>
<li><a href="#Bookmark31" title="4.3. Ordinary Least Squares (OLS) vs Gradient Descent (GD)">4.3. Ordinary Least Squares (OLS) vs Gradient Descent (GD)</a>
<ul class="toc-indentation">
<li><a href="#Bookmark32" title="4.3.1. Types of gradient descent">4.3.1. Types of gradient descent</a>
<ul class="toc-indentation">
<li><a href="#Bookmark33" title="4.3.1.1. Batch Gradient Descent">4.3.1.1. Batch Gradient Descent</a></li>
<li><a href="#Bookmark34" title="4.3.1.2. Stochastic Gradient Descent (SGD)">4.3.1.2. Stochastic Gradient Descent (SGD)</a></li>
<li><a href="#Bookmark35" title="4.3.1.3. Mini-Batch Gradient Descent">4.3.1.3. Mini-Batch Gradient Descent</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#Bookmark36" title="4.4. L1 &amp; L2 Regularization ">4.4. L1 &amp; L2 Regularization </a></li>
</ul>
</li>
<li><a href="#Bookmark37" title="5. Logistic Regression">5. Logistic Regression</a>
<ul class="toc-indentation">
<li><a href="#Bookmark38" title="5.1. Assumptions">5.1. Assumptions</a></li>
<li><a href="#Bookmark39" title="5.2. Definitions">5.2. Definitions</a>
<ul class="toc-indentation">
<li><a href="#Bookmark40" title="5.2.1. Odds">5.2.1. Odds</a></li>
<li><a href="#Bookmark41" title="5.2.2. Log Odds">5.2.2. Log Odds</a></li>
<li><a href="#Bookmark42" title="5.2.3. Odds Ratio">5.2.3. Odds Ratio</a></li>
</ul>
</li>
<li><a href="#Bookmark43" title="5.3. Logit">5.3. Logit</a></li>
<li><a href="#Bookmark44" title="5.4. Ordered Logistic Regression">5.4. Ordered Logistic Regression</a></li>
<li><a href="#Bookmark45" title="5.5. Multinomial Logistic Regression">5.5. Multinomial Logistic Regression</a></li>
</ul>
</li>
<li><a href="#Bookmark46" title="6. Probability Distribution">6. Probability Distribution</a>
<ul class="toc-indentation">
<li><a href="#Bookmark47" title="6.1. Normal Distribution">6.1. Normal Distribution</a></li>
<li><a href="#Bookmark48" title="6.2. Binomial Distribution">6.2. Binomial Distribution</a></li>
<li><a href="#Bookmark49" title="6.3. Negative Binomial Distribution">6.3. Negative Binomial Distribution</a></li>
<li><a href="#Bookmark50" title="6.4. Geometric Distribution">6.4. Geometric Distribution</a></li>
<li><a href="#Bookmark51" title="6.5. Poisson Distribution">6.5. Poisson Distribution</a></li>
</ul>
</li>
<li><a href="#Bookmark52" title="7. Conditional Probabilities">7. Conditional Probabilities</a>
<ul class="toc-indentation">
<li><a href="#Bookmark53" title="7.1. Bayes' Theorem">7.1. Bayes' Theorem</a></li>
<li><a href="#Bookmark54" title="7.2. Na&iuml;ve Bayes">7.2. Na&iuml;ve Bayes</a></li>
</ul>
</li>
<li><a href="#Bookmark55" title="8. Model Evaluation Metrics">8. Model Evaluation Metrics</a>
<ul class="toc-indentation">
<li><a href="#Bookmark56" title="8.1. Classification metrics">8.1. Classification metrics</a>
<ul class="toc-indentation">
<li><a href="#Bookmark57" title="8.1.1. Confusion matrix">8.1.1. Confusion matrix</a></li>
<li><a href="#Bookmark58" title="8.1.2. Accuracy">8.1.2. Accuracy</a></li>
<li><a href="#Bookmark59" title="8.1.3. Precision">8.1.3. Precision</a></li>
<li><a href="#Bookmark60" title="8.1.4. Recall (Sensitivity)">8.1.4. Recall (Sensitivity)</a></li>
<li><a href="#Bookmark61" title="8.1.5. Specificity">8.1.5. Specificity</a></li>
<li><a href="#Bookmark62" title="8.1.6. F1 score">8.1.6. F1 score</a></li>
<li><a href="#Bookmark63" title="8.1.7. F&beta; score">8.1.7. F&beta; score</a></li>
<li><a href="#Bookmark64" title="8.1.8. ROC (Receiver Operating Characteristic) curve">8.1.8. ROC (Receiver Operating Characteristic) curve</a></li>
</ul>
</li>
<li><a href="#Bookmark65" title="8.2. Regression metrics">8.2. Regression metrics</a>
<ul class="toc-indentation">
<li><a href="#Bookmark66" title="8.2.1. Mean Absolute Error (MAE)">8.2.1. Mean Absolute Error (MAE)</a></li>
<li><a href="#Bookmark67" title="8.2.2. Mean Square Error (MSE)">8.2.2. Mean Square Error (MSE)</a></li>
<li><a href="#Bookmark68" title="8.2.3. Root Mean Square Error (RMSE)">8.2.3. Root Mean Square Error (RMSE)</a></li>
<li><a href="#Bookmark69" title="8.2.4. R2 score">8.2.4. R2 score</a></li>
</ul>
</li>
<li><a href="#Bookmark70" title="8.3. Cross Validation">8.3. Cross Validation</a></li>
</ul>
</li>
<li><a href="#Bookmark71" title="9. Controlled Randomized Experiments">9. Controlled Randomized Experiments</a>
<ul class="toc-indentation">
<li><a href="#Bookmark72" title="9.1. Random Sampling Methods">9.1. Random Sampling Methods</a></li>
<li><a href="#Bookmark73" title="9.2. Randomized Experimental Assignment">9.2. Randomized Experimental Assignment</a></li>
<li><a href="#Bookmark74" title="9.3. Necessary Ingredients for Running Controlled Experiments">9.3. Necessary Ingredients for Running Controlled Experiments</a></li>
</ul>
</li>
</ul>
</div><p></p><p><br /></p><hr /><p><br /></p></div>
</div>
<div class="cell normal" data-type="normal">
<div class="innerCell">
<p></p></div>
</div>
</div>
<div class="columnLayout single" data-layout="single">
<div class="cell normal" data-type="normal">
<div class="innerCell">
<a name="Bookmark2"></a><h1 id="Bookmark2"><span class="nh-number">1. </span>Statistics Fundamentals</h1><a name="Bookmark3"></a><h2 id="Bookmark3"><span class="nh-number">1.1. </span>Descriptive Statistics</h2><ul><li><p><strong>P-value: </strong>the probability that we'd observe an extreme or more extreme statistic than we did given the null hypothesis was true.</p></li><li><p><strong>Expected value</strong>: weighted average of each case. Expected value use probability to tell us what outcomes to expect in the long run.</p></li><li><p><strong>Variance</strong>: the sum of the squared distance from the data to the mean</p></li><li><p><strong>Median</strong></p></li><li><p><strong>Mode</strong></p></li><li><p><strong>Percentile</strong>/<strong>Quartiles</strong>/<strong>Deciles</strong></p></li><li><p><strong>Outlier</strong>: </p><ul><li><p><strong>1.5 IQR rule</strong> for outliers - a data point is an outlier if it's more than 1.5 IQR above the 3rd quartile or below the 1st quartile</p></li></ul></li></ul><a name="Bookmark4"></a><h2 id="Bookmark4"><span class="nh-number">1.2. </span>Law of Large Numbers (LLN)</h2><p style="margin-left: 30.0px;">In probability theory, the LLN is a theorem that describes the results of performing the same experiment a large number of times. According to the law, the average of the results obtained from a large number of trials should be close to the expected value, and will tend to become closer as more trials are performed.</p><a name="Bookmark5"></a><h2 id="Bookmark5"><span class="nh-number">1.3. </span>Central Limit Theorem (CLT)</h2><p style="margin-left: 30.0px;">As the sample size becomes larger, the sample mean distribution (sampling distribution) will be closed to normal distribution, no matter what the shape of the population distribution. </p><ul><li>Sample <strong>Sum</strong> distribution ~ N (&mu;', &sigma;'):<ul><li>&mu;' = n * &mu;</li><li>&sigma;' = &sigma; * n**(1/2)</li></ul></li><li>Sample <strong>Mean</strong> distribution ~ N (&mu;', &sigma;'):<ul><li>&mu;' = &mu;</li><li>&sigma;' = &sigma; / n**(1/2)</li></ul></li></ul><a name="Bookmark6"></a><h2 id="Bookmark6"><span class="nh-number">1.4. </span>Matrix Determinant </h2><a name="Bookmark7"></a><h3 id="Bookmark7"><span class="nh-number">1.4.1. </span>3x3 matrix</h3>    
\[ \det \begin{pmatrix}a&amp;b&amp;c\\ d&amp;e&amp;f\\ g&amp;h&amp;i\end{pmatrix}=a\cdot \det \begin{pmatrix}e&amp;f\\ h&amp;i\end{pmatrix}-b\cdot \det \begin{pmatrix}d&amp;f\\ g&amp;i\end{pmatrix}+c\cdot \det \begin{pmatrix}d&amp;e\\ g&amp;h\end{pmatrix} \]
<p><br /></p><p><br /></p><hr /><p><br /></p></div>
</div>
</div>
<div class="columnLayout single" data-layout="single">
<div class="cell normal" data-type="normal">
<div class="innerCell">
<a name="Bookmark8"></a><h1 id="Bookmark8"><span class="nh-number">2. </span>Hypothesis Testing</h1><a name="Bookmark9"></a><h2 id="Bookmark9"><span class="nh-number">2.1. </span>Terms</h2><ul><li><strong>P-value</strong>: Given null hypothesis is true, the probability of observed outcomes</li><li><strong>Confidence Interval:</strong> The range within which the mean is expected to fall in multiple trails of the experiment.</li><li><strong>Type-I error</strong>: (&alpha;) Falsely reject a true null hypothesis &ndash; False positive</li><li><p class="auto-cursor-target"><strong>Type-II error</strong>: (&beta;) Fail to reject a a false null hypothesis &ndash; False negative</p><div class="table-wrap"><table class="relative-table wrapped confluenceTable" style="width: 35.2787%;; font-size:1.0em"><colgroup><col /><col /><col /></colgroup><tbody><tr><th class="confluenceTh"><br /></th><th class="confluenceTh">True Null Hypothesis</th><th class="confluenceTh">False Null Hypothesis</th></tr><tr><th class="confluenceTh">Reject Null Hypothesis</th><td class="confluenceTd" style="padding:0.5em">Type-I error (<strong>&alpha;</strong>)</td><td class="confluenceTd" style="padding:0.5em">correct (power)</td></tr><tr><th class="confluenceTh">Accept Null Hypothesis</th><td class="confluenceTd" style="padding:0.5em">correct</td><td class="confluenceTd" style="padding:0.5em">Type-II error(<strong>&beta;</strong>)</td></tr></tbody></table></div></li><li><strong>Practical Significance:</strong> The magnitude of the difference. Can be examined by computing <strong>Cohen's <em>d</em>,</strong> which is the difference between the two observed sample means in standard deviation units: </li></ul><p><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" height="388" src="img_1.png" data-image-src="/download/attachments/1239118772/2020-02-21_15-15-17.png?version=1&amp;modificationDate=1582327023920&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1355665935" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="2020-02-21_15-15-17.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" width="624" /></span></p><a name="Bookmark10"></a><h2 id="Bookmark10"><span class="nh-number">2.2. </span><strong>Power</strong> in significance test:</h2><p style="margin-left: 30.0px;">Power = 1-&beta; = Pr(Rejecting null hypo | Null hypo is false) = 1 - Pr(Accept null hypo | Null hypo is false) = Pr(Not making Type-II error) </p><p style="margin-left: 30.0px;">Usually choose <strong>0.8</strong> or higher power.</p><p style="margin-left: 60.0px;"><br /></p><p style="margin-left: 30.0px;">Four primary factors affect power:</p><ol><li style="list-style-type: none;background-image: none;"><ul><li>Significance level (<strong>&alpha;</strong>)</li><li>Sample size (<strong>n</strong>)</li><li>Variability, or variance, in the measured response variable (<strong>&sigma;</strong> or <strong>s</strong>)</li><li>Magnitude of the effect of the variable (effect size <strong>&epsilon;</strong>)</li></ul></li></ol><p><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" height="353" src="img_2.png" data-image-src="/download/attachments/1239118772/Img2020-02-24_19-29-08.png?version=1&amp;modificationDate=1582601384617&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1355675965" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Img2020-02-24_19-29-08.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" width="624" /></span></p><a name="Bookmark11"></a><h2 id="Bookmark11"><span class="nh-number">2.3. </span>Sample Size</h2><p><a class="external-link" href="https://online.stat.psu.edu/stat414/node/306/" rel="nofollow">https://online.stat.psu.edu/stat414/node/306/</a></p><p>Estimate sample size given desired alpha and beta.</p><a name="Bookmark12"></a><h3 id="Bookmark12"><span class="nh-number">2.3.1. </span>Estimating a mean</h3><ul><li>The <strong>sample size</strong> necessary <strong>for estimating a population mean</strong> <em>&mu;</em> with <span style="color: inherit;">(1&minus;<em>&alpha;</em>)100% confidence and </span>error no larger than <span style="color: inherit;"><strong><em>&epsilon;</em></strong> </span>is:</li></ul><p style="margin-left: 90.0px;"> <span class="confluence-embedded-file-wrapper"><img class="confluence-embedded-image confluence-external-resource" alt="eqn" src="" data-image-src="https://online.stat.psu.edu/stat414/sites/onlinecourses.science.psu.edu.stat414/files/lesson34/Lesson34_Eqn03/index.gif" /></span>   where we can use <strong style="letter-spacing: 0.0px;">z</strong><em style="letter-spacing: 0.0px;"><strong><sub>&alpha;/2</sub></strong> to replace <strong>t</strong><sub><em><strong>&alpha;/2, n-1</strong> .   </em></sub></em></p><ul><li>How to estimate <strong>s</strong>? &ndash; <strong>Empirical Rule</strong>  </li></ul><pre><br /></pre><p style="margin-left: 30.0px;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-external-resource" alt="drawing" width="250" src="" data-image-src="https://online.stat.psu.edu/stat414/sites/onlinecourses.science.psu.edu.stat414/files/lesson34/Lesson34_Drawing01/index.gif" /></span>    <span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-external-resource" alt="drawing" width="250" src="" data-image-src="https://online.stat.psu.edu/stat414/sites/onlinecourses.science.psu.edu.stat414/files/lesson34/Lesson34_Drawing02a/index.gif" /></span></p><a name="Bookmark13"></a><h3 id="Bookmark13"><span class="nh-number">2.3.2. </span>Estimating a proportion for a large population</h3><ul><li><span style="color: rgb(0,0,0);"><span style="color: rgb(0,0,0);">An </span><strong>approximate </strong><span style="color: rgb(0,0,0);">(</span><strong>1&minus;</strong><em><strong>&alpha;</strong></em><strong>)100% confidence interval for a proportion <em>p</em></strong><span style="color: rgb(0,0,0);"> of a large population is:</span></span></li></ul><p><br /></p>    
\[ \hat{p}\pm z_{\alpha/2}\sqrt{\dfrac{\hat{p}(1-\hat{p})}{n}} \]
<p><br /></p><ul><li><span style="color: rgb(0,0,0);">The </span><strong>sample size</strong><span style="color: rgb(0,0,0);"> necessary </span><strong>for estimating a population proportion</strong><span style="color: rgb(0,0,0);"> </span><em>p</em><span style="color: rgb(0,0,0);"> of a large population with </span><span style="color: rgb(0,0,0);">(1&minus;<em>&alpha;</em>)100% confidence and </span><span style="color: rgb(0,0,0);">error no larger than </span><span style="color: rgb(0,0,0);"><em>&epsilon;</em> </span><span style="color: rgb(0,0,0);">is:</span></li></ul><p><br /></p>    
\[ n=\dfrac{z^2_{\alpha/2}\hat{p}(1-\hat{p})}{\epsilon^2} \]
<p><br /></p><ul><li><p class="auto-cursor-target">How to estimate </p>    
\[ \hat{p}(1-\hat{p}) \]
<p>Set p(1-p) = 1/4, its maximum when p = 1/2</p></li></ul><p style="margin-left: 60.0px;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-external-resource" alt="drawing" width="300" src="" data-image-src="https://online.stat.psu.edu/stat414/sites/onlinecourses.science.psu.edu.stat414/files/lesson34/Lesson34_Drawing03/index.gif" /></span></p><a name="Bookmark14"></a><h3 id="Bookmark14"><span class="nh-number">2.3.3. </span>Estimating a proportion for a small population (N is small)</h3><ul><li><p class="auto-cursor-target"><span style="color: rgb(0,0,0);">An </span><strong>approximate </strong><span style="color: rgb(0,0,0);">(</span><strong>1&minus;</strong><em><strong>&alpha;</strong></em><strong>)100% confidence interval for a proportion <em>p</em></strong><span style="color: rgb(0,0,0);"> of a small population is:</span></p>    
\[ \hat{p}\pm z_{\alpha/2}\sqrt{\dfrac{\hat{p}(1-\hat{p})}{n} \cdot \dfrac{N-n}{N-1}} \]
<p class="auto-cursor-target"><span style="color: rgb(0,0,0);">Noting that if the sample </span><strong><em>n</em></strong><span style="color: rgb(0,0,0);"> is much smaller than the population size </span><strong><em>N</em></strong><span style="color: rgb(0,0,0);">, that is, if </span><em>n</em><span style="color: rgb(0,0,0);"> &lt;&lt; </span><em>N</em><span style="color: rgb(0,0,0);">, then <strong>(N-n)/(N-1) &asymp; 1</strong>, <span style="color: rgb(0,0,0);">and the confidence interval for </span><em>p</em><span style="color: rgb(0,0,0);"> of a small population becomes quite similar to the confidence interval for </span><em>p</em><span style="color: rgb(0,0,0);"> of a large population.</span></span></p><p class="auto-cursor-target"><span style="color: rgb(0,0,0);"><span style="color: rgb(0,0,0);"><br /></span></span></p></li><li><p class="auto-cursor-target"><span style="color: rgb(0,0,0);"><span style="color: rgb(0,0,0);"><span style="color: rgb(0,0,0);">The </span><strong>sample size</strong><span style="color: rgb(0,0,0);"> necessary </span><strong>for estimating a population proportion</strong><span style="color: rgb(0,0,0);"> </span><em>p</em><span style="color: rgb(0,0,0);"> of a small finite population <strong>N</strong> with </span><span style="color: rgb(0,0,0);">(1&minus;<strong><em>&alpha;</em></strong>)100% confidence and </span><span style="color: rgb(0,0,0);">error no larger than </span><span style="color: rgb(0,0,0);"><strong><em>&epsilon;</em></strong> </span><span style="color: rgb(0,0,0);">is:</span></span></span></p>    
\[ n=\dfrac{z^2_{\alpha/2}\hat{p}(1-\hat{p})/\epsilon^2}{\dfrac{N-1}{N}+\dfrac{z^2_{\alpha/2}\hat{p}(1-\hat{p})}{N\epsilon^2}} \]
<p class="auto-cursor-target"><span style="color: rgb(0,0,0);"><span style="color: rgb(0,0,0);">or</span></span></p>    
\[ n=\dfrac{m}{1+\dfrac{m-1}{N}} \]
<p class="auto-cursor-target"><span style="color: rgb(0,0,0);"><span style="color: rgb(0,0,0);">where</span></span></p>    
\[ m=\dfrac{z^2_{\alpha/2}\hat{p}(1-\hat{p})}{\epsilon^2} \]
<p class="auto-cursor-target"><span style="color: rgb(0,0,0);"><span style="color: rgb(0,0,0);"><br /></span></span></p></li></ul><a name="Bookmark15"></a><h2 id="Bookmark15"><span class="nh-number">2.4. </span>Steps</h2><ol><li>Write hypothesis</li><li>Check conditions (<strong>Random</strong>, <strong>Normal</strong>, <strong>Independence</strong>)</li><li>Calculate t or z statistics</li><li>Get p-value (one-tailed or two-tailed)</li><li>Compare p-value to &alpha; (significance level)<ol><li>Type-I or Type-II error</li><li>Power</li></ol></li><li>Make a conclusion</li></ol><a name="Bookmark16"></a><h2 id="Bookmark16"><span class="nh-number">2.5. </span>Types</h2><a name="Bookmark17"></a><h3 id="Bookmark17"><span class="nh-number">2.5.1. </span><strong>Test on</strong> a population proportion</h3><ul><li>Conditions for a z-test:<ul><li><strong>Random</strong>: the data needs to come from a random sample or randomized experiment.</li><li><strong>Normal</strong>: the sampling distribution of <strong>p (the sample proportion)</strong> needs to be approximately normal &ndash; needs at least <strong>10</strong> expected successes and <strong>10</strong> expected failures:<ul><li>np &gt;= 10</li><li>n(1-p) &gt;= 10</li></ul></li><li><strong>Independence</strong>: individual observation needs to be independent. If sampling <strong>without replacement</strong>, the sample size shouldn't be more than <strong>10%</strong> of the population:<br /><ul><li>use replacement</li><li>OR n &lt;= 10% population</li></ul></li></ul></li><li>Calculate a z statistic: <strong>Delta / Std Error</strong><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-thumbnail" width="130" src="img_3.png" data-image-src="/download/attachments/1239118772/image2019-12-24_12-13-59.png?version=1&amp;modificationDate=1577218439697&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1293389445" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image2019-12-24_12-13-59.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="57" /></span></li></ul><a name="Bookmark18"></a><h3 id="Bookmark18"><span class="nh-number">2.5.2. </span>Test on a population mean</h3><ul><li>Conditions for a z-test:<ul><li><strong>Random</strong>: a random sampling or randomized experiment should be used to obtain the data</li><li><strong>Normal</strong>: the sampling distribution of <strong>x (the sample mean)</strong> needs to be approximately normal. It is true if the <strong>parent </strong><strong>population</strong> is <strong>normal</strong> or if the sample size is reasonably large (<strong>n &gt;= 30</strong>):<ul><li>parent population is normal</li><li>OR n &gt;= 30</li><li>OR if unknown parent population distribution and n &lt; 30 &ndash; the big idea is that we need to graph the sample data when n &lt; 30 and make a decision about the normal condition based on the appearance of the sample data (symmetric without outlier)</li></ul></li><li><strong>Independence</strong>: Individual observation needs to be independent. If sampling without replacement, the sample size shouldn't be more than 10% of the population:<ul><li>use replacement</li><li>OR n &lt;= 10% of population</li></ul></li></ul></li><li>Calculate a z or t statistics: <strong>Delta / Std Error  <span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-thumbnail" width="110" src="img_4.png" data-image-src="/download/attachments/1239118772/image2019-12-24_12-43-47.png?version=1&amp;modificationDate=1577220227270&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1293389467" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image2019-12-24_12-43-47.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="63" /></span></strong></li><li>When to use <strong>z</strong> or <strong>t</strong> statistic:<ul><li>if known population variance, use <strong>population</strong> standard deviation: z statistic</li><li>if DON'T known population variance, use <strong>sample</strong> standard deviation: t statistic<br /><br /><span class="confluence-embedded-file-wrapper image-left-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-thumbnail image-left" width="200" src="img_5.png" data-image-src="/download/attachments/1239118772/Untitled%20picture%200.png?version=1&amp;modificationDate=1577305112960&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1293390133" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Untitled picture 0.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="195" /></span>    <span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image" height="358" src="img_6.png" data-image-src="/download/attachments/1239118772/image2019-12-24_12-51-40.png?version=1&amp;modificationDate=1577220701563&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1293389468" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image2019-12-24_12-51-40.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" width="624" /></span></li></ul></li></ul><a name="Bookmark19"></a><h3 id="Bookmark19"><span class="nh-number">2.5.3. </span>Test on two sample proportions</h3><ul><li>Calculate z statistic: <strong>Delta / Std Error</strong></li></ul><p style="margin-left: 30.0px;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image" height="249" src="img_7.png" data-image-src="/download/attachments/1239118772/Untitled%20picture%201.png?version=1&amp;modificationDate=1577305171793&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1293390134" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Untitled picture 1.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" width="480" /></span></p><p style="margin-left: 30.0px;"><br /></p><p style="margin-left: 30.0px;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image" width="400" src="img_8.png" data-image-src="/download/attachments/1239118772/Untitled%20picture.png?version=3&amp;modificationDate=1577304972000&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1293389470" data-linked-resource-version="3" data-linked-resource-type="attachment" data-linked-resource-default-alias="Untitled picture.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="81" /></span></p><p style="margin-left: 30.0px;"><br /></p><a name="Bookmark20"></a><h3 id="Bookmark20"><span class="nh-number">2.5.4. </span><strong>Test on paired means</strong></h3><ul><li>In this situation, our measurements differences are di, df = n-1</li><li>calculate t statistic: <strong>Delta / Std Error  <span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-thumbnail" width="100" src="img_9.png" data-image-src="/download/attachments/1239118772/image2019-12-25_11-57-16.png?version=1&amp;modificationDate=1577303836513&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1293390122" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image2019-12-25_11-57-16.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="61" /></span></strong></li></ul><a name="Bookmark21"></a><h3 id="Bookmark21"><span class="nh-number">2.5.5. </span><strong>Test on two independent sample means</strong></h3><ul><li>When population variances are <strong>equal</strong>:<ul><li>df = n+m-1</li><li><p class="auto-cursor-target">calculate t statistic: <strong><strong>Delta / Std Error  <span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-thumbnail" width="170" src="img_10.png" data-image-src="/download/attachments/1239118772/Untitled%20picture%202.png?version=1&amp;modificationDate=1577305230470&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1293390135" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Untitled picture 2.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="69" /></span>,  <span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-thumbnail" width="190" src="img_11.png" data-image-src="/download/attachments/1239118772/Untitled%20picture%203.png?version=1&amp;modificationDate=1577305274743&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1293390136" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Untitled picture 3.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="52" /></span></strong></strong></p><p class="auto-cursor-target"><strong><strong><br /></strong></strong></p></li></ul></li><li><p class="auto-cursor-target">When population variances are <strong>not equal</strong>:</p><ul><li><p class="auto-cursor-target">adjusted df (integer portion of r): <span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-thumbnail" width="180" src="img_12.png" data-image-src="/download/attachments/1239118772/Untitled%20picture%204.png?version=1&amp;modificationDate=1577305366583&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1293390137" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Untitled picture 4.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="105" /></span></p></li><li><p class="auto-cursor-target">calculate t statistic: <strong>Delta / Std Error</strong> <span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-thumbnail" width="180" src="img_13.png" data-image-src="/download/attachments/1239118772/Untitled%20picture%205.png?version=1&amp;modificationDate=1577305489600&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1293390139" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Untitled picture 5.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="78" /></span></p></li></ul></li></ul><a name="Bookmark22"></a><h3 id="Bookmark22"><span class="nh-number">2.5.6. </span>Test on the distribution of categorical data: Chi-squared test &chi;<sup><sub>2 </sub></sup></h3><ul><li>Data come from one sample &rarr; test of <strong>independence</strong></li><li>Data come from separate samples &rarr; test of <strong>homogeneity</strong></li><li>Conditions:<ul><li><strong>Random</strong></li><li><strong>Normal</strong>: Large number (&gt;= 5 per cell)</li><li><strong>Independence</strong>: (sample &lt;= 10% of population)</li></ul></li><li>Goodness-of-fit test:<ul><li>df = n-1</li></ul></li><li>Relationship test:<ul><li>df = (# of rows - 1)*(# of columns - 1)</li></ul></li><li>Two variable association test:<ul><li>df = (# of rows - 1)*(# of columns - 1)<br /><br /></li></ul></li></ul><p style="margin-left: 30.0px;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image" width="450" src="img_14.png" data-image-src="/download/attachments/1239118772/Untitled%20picture%206.png?version=1&amp;modificationDate=1577306791293&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1293390141" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Untitled picture 6.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="152" /></span></p><p style="margin-left: 30.0px;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-thumbnail" width="300" src="img_15.png" data-image-src="/download/attachments/1239118772/Untitled%20picture%207.png?version=1&amp;modificationDate=1577306852740&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1293390142" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Untitled picture 7.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="56" /></span></p><a name="Bookmark23"></a><h3 id="Bookmark23"><span class="nh-number">2.5.7. </span>Test on one variance: Chi-squared test &chi;<sup style="letter-spacing: -0.006em;"><sub>2 </sub></sup></h3><p style="margin-left: 30.0px;"><span style="color: rgb(0,0,0);">If you have a random sample of size </span><em>n</em><span style="color: rgb(0,0,0);"> from a </span><strong>normal population </strong><span style="color: rgb(0,0,0);">with (unknown) mean </span><em>&mu;</em><span style="color: rgb(0,0,0);"> and variance </span><em>&sigma;</em><sup>2</sup><span style="color: rgb(0,0,0);">, then:</span></p>    
\[ \chi^2=\dfrac{(n-1)S^2}{\sigma^2} \]
<p style="margin-left: 30.0px;"><span style="color: rgb(0,0,0);">follows a <strong>chi-square distribution</strong> with </span><em>n</em><span style="color: rgb(0,0,0);"><em>&minus;1</em> degrees of freedom.</span></p><a name="Bookmark24"></a><h3 id="Bookmark24"><span class="nh-number">2.5.8. </span>Test on two variance: F-test</h3><p style="margin-left: 30.0px;">Can be used to test the validation of the assumption of <strong>equal variance</strong> that needs when performing two-sample t-test.</p><p style="margin-left: 60.0px;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-external-resource" alt="eqn" width="300" src="" data-image-src="https://online.stat.psu.edu/stat414/sites/onlinecourses.science.psu.edu.stat414/files/lesson40/Lesson40_Eqn13/index.gif" /></span><span style="color: rgb(0,0,0);">follows an </span><em>F</em><span style="color: rgb(0,0,0);"> distribution with  </span><em>n</em><span style="color: rgb(0,0,0);">&minus;1 numerator degrees of freedom and </span><em>m</em><span style="color: rgb(0,0,0);">&minus;1 denominator degrees of freedom.</span></p><p style="margin-left: 30.0px;">If we're interested in testing the null hypothesis:</p>    
\[ \chi^2=\dfrac{(n-1)S^2}{\sigma^2} \]
<p style="text-align: left;margin-left: 30.0px;"><span style="letter-spacing: 0.0px;text-align: left;">against any of the alternative hypotheses:</span></p>    
\[ H_A:\sigma^2_X \neq \sigma^2_Y,\quad H_A:\sigma^2_X &gt;\sigma^2_Y,\text{ or }H_A:\sigma^2_X &lt;\sigma^2_Y \]
<p style="text-align: left;margin-left: 30.0px;">we can use the test statistic:</p>    
\[ F=\dfrac{S^2_X}{S^2_Y} \]
<p style="margin-left: 30.0px;">and follow the standard hypothesis testing procedures. When doing so, we might also want to recall this important fact about the <strong><em>F</em>-distribution</strong>:</p>    
\[ F_{1-(\alpha/2)}(n-1,m-1)=\dfrac{1}{F_{\alpha/2}(m-1,n-1)} \]
<p style="margin-left: 30.0px;">so that when we use the critical value approach for a two-sided alternative:</p>    
\[ H_A:\sigma^2_X \neq \sigma^2_Y \]
<p style="text-align: left;margin-left: 30.0px;">we reject if the test statistic <em style="letter-spacing: 0.0px;text-align: left;">F</em> is too large:</p>    
\[ F \geq F_{\alpha/2}(n-1,m-1) \]
<p style="text-align: left;margin-left: 30.0px;">or if the test statistic <em style="letter-spacing: 0.0px;text-align: left;">F</em> is too small:</p>    
\[ F \leq F_{1-(\alpha/2)}(n-1,m-1)=\dfrac{1}{F_{\alpha/2}(m-1,n-1)} \]
<a name="Bookmark25"></a><h1 id="Bookmark25"><span class="nh-number">3. </span>ANOVA</h1><a name="Bookmark26"></a><h2 id="Bookmark26"><span class="nh-number">3.1. </span>Assumptions</h2><ul><li>Independence</li><li>Normality</li><li>Equal group variances</li></ul><a name="Bookmark27"></a><h2 id="Bookmark27"><span class="nh-number">3.2. </span>ANOVA Table</h2><ul><li>Analysis of variance, is a collection of methods for comparing multiple means across different groups</li><li><strong>y</strong> groups, <strong>x</strong> samples in each group:<ul><li>SST &ndash; Total Sum of Squares (df = x * y - 1)</li><li>SSW &ndash; Total Sum of Squares Within (df = y * (x-1))</li><li>SSB - Total Sum of Squares Between (df = y - 1)</li><li>SST = SSW + SSB</li></ul></li></ul><p style="margin-left: 60.0px;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-external-resource" alt="anova table" width="500" src="" data-image-src="https://online.stat.psu.edu/stat414/sites/onlinecourses.science.psu.edu.stat414/files/lesson41/Lesson41_Graphic12/index.gif" /></span></p><p style="margin-left: 60.0px;"><br /></p><p style="margin-left: 60.0px;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-external-resource" alt="data" width="400" src="" data-image-src="https://online.stat.psu.edu/stat414/sites/onlinecourses.science.psu.edu.stat414/files/lesson41/Lesson41_Graphic14/index.gif" /></span></p>    
\[ SS(E)=\sum\limits_{i=1}^{m}\sum\limits_{j=1}^{n_i} (X_{ij}-\bar{X}_{i.})^2 \]
    
\[ SS(T)=\sum\limits_{i=1}^{m}\sum\limits_{j=1}^{n_i}(\bar{X}_{i.}-\bar{X}_{..})^2 \]
    
\[ SS(TO)=\sum\limits_{i=1}^{m}\sum\limits_{j=1}^{n_i} (X_{ij}-\bar{X}_{..})^2 \]
<ul><li><p class="auto-cursor-target"><span style="color: rgb(0,0,0);">If </span><em>X</em><sub><em>ij</em> </sub><span style="color: rgb(0,0,0);">~ </span><em>N</em><span style="color: rgb(0,0,0);">(</span><em>&mu;</em><span style="color: rgb(0,0,0);">, </span><em>&sigma;</em><sup>2</sup><span style="color: rgb(0,0,0);"><span style="color: rgb(0,0,0);">), then:</span></span></p>    
\[ F=\dfrac{SST/(m-1)}{SSE/(n-m)}=\dfrac{MST}{MSE} \sim F(m-1,n-m) \]
</li></ul><a name="Bookmark28"></a><h1 id="Bookmark28"><span class="nh-number">4. </span>Linear Models</h1><a name="Bookmark29"></a><h2 id="Bookmark29"><span class="nh-number">4.1. </span>Assumptions (<strong>LINE</strong>):</h2><ul><li>The mean of the responses, <em>E</em>(<em>Y<sub>i</sub></em>), is a <strong><span style="color: rgb(255,0,0);">L</span>inear function</strong> of the <em>x<sub>i</sub></em>.</li><li>The errors, <em>&epsilon;<sub>i</sub></em>, and hence the responses <em>Y<sub>i</sub></em>, are <strong><span style="color: rgb(255,0,0);">I</span>ndependent</strong>.</li><li>The errors, <em>&epsilon;<sub>i</sub></em>, and hence the responses <em>Y<sub>i</sub></em>, are <strong><span style="color: rgb(255,0,0);">N</span>ormally distributed</strong>.</li><li>The errors, <em>&epsilon;<sub>i</sub></em>, and hence the responses <em>Y<sub>i</sub></em>, have <strong><span style="color: rgb(255,0,0);">E</span>qual variances</strong> (<em>&sigma;</em><sup>2</sup>) for all <em>x</em> values.</li></ul><a name="Bookmark30"></a><h2 id="Bookmark30"><span class="nh-number">4.2. </span>Least-Squares Linear Regression</h2><ul><li>Y = &beta;x + &alpha;<ul><li>&beta; = r*(s<sub>y</sub>/s<sub>x</sub>) = s<sub>x</sub>*s<sub>y</sub>/s<sub>xx</sub></li></ul></li></ul><p style="margin-left: 60.0px;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-thumbnail" width="200" src="img_16.png" data-image-src="/download/attachments/1239118772/Untitled%20picture%209.png?version=1&amp;modificationDate=1578811837107&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1299668328" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Untitled picture 9.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="67" /></span></p><p style="margin-left: 60.0px;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-thumbnail" width="150" src="img_17.png" data-image-src="/download/attachments/1239118772/Untitled%20picture%2010.png?version=1&amp;modificationDate=1578811870273&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1299668329" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Untitled picture 10.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="70" /></span></p><a name="Bookmark31"></a><h2 id="Bookmark31"><span class="nh-number">4.3. </span>Ordinary Least Squares (OLS) vs Gradient Descent (GD)</h2><ul><li><span>The OLS estimate the slope 𝛽 and intercept 𝛼 of the straight line by minimizing the <strong>sum of squared residuals (SSE)</strong>.</span><span><br /></span><br /><span><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-external-resource" width="200" src="" data-image-src="https://miro.medium.com/max/520/1*y-LRgpDIzNXNx0BBovvZ0g.png" /></span><br /></span><br /><span><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-external-resource" width="250" src="" data-image-src="https://miro.medium.com/max/618/1*457Or2mdZQRCeeQN1DLsZg.png" /></span><br /></span></li><li><p class="hn ho dt bg hp b hq hr hs ht hu hv hw hx hy hz ia eq">Gradient descent approach aims to minimize a <strong>cost function</strong> by iterations. The cost function for the simple linear regression is equivalent to the average of squared residuals.<br /><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-external-resource" width="250" src="" data-image-src="https://miro.medium.com/max/590/1*xGe4JKlSDK0XnUaIXcbDfg.png" /></span> <span>where </span><em class="kr">m</em><span> is the batch size.</span></p><p class="hn ho dt bg hp b hq hr hs ht hu hv hw hx hy hz ia eq"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image confluence-external-resource" width="350" src="" data-image-src="https://miro.medium.com/max/900/1*G3evFxIAlDchOx5Wl7bV5g.png" /></span> <span>where &alpha; is a learning rate / how big a step take to downhill.</span></p></li></ul><a name="Bookmark32"></a><h3 id="Bookmark32"><span class="nh-number">4.3.1. </span>Types of gradient descent</h3><a name="Bookmark33"></a><h4 class="ia ib fv ar ic b id ie if ig ih ii ij ik il im in es" id="Bookmark33"><span class="nh-number">4.3.1.1. </span><span class="ic io">Batch Gradient Descent</span></h4><ul><li class="ia ib fv ar ic b id ie if ig ih ii ij ik il im in ju jv jw" style="list-style-type: disc;">In the batch gradient descent, to calculate the gradient of the cost function, we need to sum all training examples for each steps</li><li class="ia ib fv ar ic b id jx if jy ih jz ij ka il kb in ju jv jw" style="list-style-type: disc;">If we have 3 millions samples (m training examples) then the gradient descent algorithm should sum 3 millions samples for every epoch. To move a single step, we have to calculate each with 3 million times!</li><li class="ia ib fv ar ic b id jx if jy ih jz ij ka il kb in ju jv jw" style="list-style-type: disc;">Batch Gradient Descent is not good fit for large datasets</li></ul><a name="Bookmark34"></a><h4 class="ia ib fv ar ic b id ie if ig ih ii ij ik il im in es" id="Bookmark34"><span class="nh-number">4.3.1.2. </span><span class="ic io">Stochastic Gradient Descent (SGD)</span></h4><ul><li class="ia ib fv ar ic b id ie if ig ih ii ij ik il im in ju jv jw" style="list-style-type: disc;">In stochastic Gradient Descent, we use one example or one training sample at each iteration instead of using whole dataset to sum all for every steps</li><li class="ia ib fv ar ic b id jx if jy ih jz ij ka il kb in ju jv jw" style="list-style-type: disc;">SGD is widely used for larger dataset trainings and computationally faster and can be trained in parallel</li><li class="ia ib fv ar ic b id jx if jy ih jz ij ka il kb in ju jv jw" style="list-style-type: disc;">Need to randomly shuffle the training examples before calculating it</li></ul><a name="Bookmark35"></a><h4 class="ia ib fv ar ic b id ie if ig ih ii ij ik il im in es" id="Bookmark35"><span class="nh-number">4.3.1.3. </span><span class="ic io">Mini-Batch Gradient Descent</span></h4><ul><li class="ia ib fv ar ic b id ie if ig ih ii ij ik il im in ju jv jw" style="list-style-type: disc;">It is similar like SGD, it uses <span class="ic io"><em class="jt">n</em> </span>samples instead of 1 at each iteration.</li></ul><a name="Bookmark36"></a><h2 id="Bookmark36"><span class="nh-number">4.4. </span>L1 &amp; L2 Regularization </h2><ul><li>L1 - LASSO<ul><li>Subjective function: min&sum;(𝑦 &minus;𝑥𝛽)<sup>2</sup> +𝜆&sum;|𝛽|</li></ul></li><li>L2 - Ridge<ul><li>Subjective function: min<span>&sum;</span>(𝑦 &minus;𝑥𝛽)<sup>2</sup><span> </span><span>+𝜆</span><span>&sum;</span><span>𝛽<sup>2</sup></span> </li></ul></li></ul><div class="table-wrap"><table class="relative-table confluenceTable" style="width: 50.1385%;; font-size:1.0em"><colgroup><col style="" /><col style="" /></colgroup><tbody><tr><th class="confluenceTh"><p><span>Ridge regularization </span></p></th><th class="confluenceTh"><span>LASSO regularization </span></th></tr><tr><td class="confluenceTd" style="padding:0.5em"><p><span>Regularization term is in square value </span></p></td><td class="confluenceTd" style="padding:0.5em"><p><span>Regularization term is in absolute value </span></p></td></tr><tr><td class="confluenceTd" style="padding:0.5em"><p><span>&lambda; controls the size of coefficients and amount of regularization </span></p></td><td class="confluenceTd" style="padding:0.5em"><p><span>&lambda; controls amounts of regularization </span></p></td></tr><tr><td class="confluenceTd" style="padding:0.5em"><p><span>Shrink the magnitude of coefficients fast, will not </span>get rid of irrelevant features but rather minimize their impact on the trained model.</p></td><td class="confluenceTd" style="padding:0.5em"><p><span>Least absolute shrinkage and select feature, </span>not only punishing high values of the <span style="letter-spacing: 0.0px;">coefficients &beta; but a</span>ctually setting them to zero if they are not relevant.</p></td></tr></tbody></table></div><p><span><br /></span></p><a name="Bookmark37"></a><h1 id="Bookmark37"><span class="nh-number">5. </span>Logistic Regression</h1><a name="Bookmark38"></a><h2 id="Bookmark38"><span class="nh-number">5.1. </span>Assumptions</h2><ol><li><strong>APPROPRIATE OUTCOME STRUCTURE</strong>: Binary logistic regression requires the dependent variable to be binary and ordinal logistic regression requires the dependent variable to be ordinal.</li><li><strong>OBSERVATION INDEPENDENCE</strong>: Logistic regression requires the observations to be independent of each other.  In other words, the observations should not come from repeated measurements or matched data.</li><li><strong>THE ABSENCE OF MULTICOLLINEARITY</strong>: Logistic regression requires there to be little or no multicollinearity among the independent variables. This means that the independent variables should not be too highly correlated with each other.</li><li><strong>LINEARITY OF INDEPENDENT VARIABLES AND LOG ODDS</strong>: Logistic regression assumes linearity of independent variables and log odds. Although this analysis does not require the dependent and independent variables to be related linearly, it requires that the independent variables are linearly related to the log odds.</li><li><strong>A LARGE SAMPLE SIZE</strong>: Logistic regression typically requires a large sample size. A general guideline is that you need at minimum of 10 cases with the least frequent outcome for each independent variable in your model. For example, if you have 5 independent variables and the expected probability of your least frequent outcome is .10, then you would need a minimum sample size of 500= (10*5 / .10).</li></ol><a name="Bookmark39"></a><h2 id="Bookmark39"><span class="nh-number">5.2. </span>Definitions</h2><a name="Bookmark40"></a><h3 id="Bookmark40"><span class="nh-number">5.2.1. </span><span>Odds</span></h3><p style="margin-left: 30.0px;">Showing that odds are ratios.</p><pre>     odds = p/(1 - p)</pre><a name="Bookmark41"></a><h3 id="Bookmark41"><span class="nh-number">5.2.2. </span><span>Log Odds</span></h3><p style="margin-left: 30.0px;">Natural log of the odds, also known as a logit.</p><pre>     log odds = logit = log(p/(1 - p))</pre><a name="Bookmark42"></a><h3 id="Bookmark42"><span class="nh-number">5.2.3. </span><span>Odds Ratio</span></h3><p style="margin-left: 30.0px;">Showing that odds ratios are actually ratios of ratios.</p><pre>                  odds1     p1/(1 - p1)
     odds_ratio = ----- = -------------
                  odds2     p2/(1 - p2)</pre><p style="margin-left: 30.0px;"><span>Computing Odds Ratio from Logistic Regression Coefficient</span></p><pre>     odds_ratio = exp(b)</pre><p style="margin-left: 30.0px;"><span>Computing Probability from Logistic Regression Coefficients</span></p><pre>     probability = exp(Xb)/(1 + exp(Xb))</pre><p style="margin-left: 30.0px;">Where <span>Xb</span> is the linear predictor.</p><a name="Bookmark43"></a><h2 id="Bookmark43"><span class="nh-number">5.3. </span>Logit</h2><p style="margin-left: 30.0px;">There is a direct relationship between the coefficients produced by <strong>logit</strong> and the odds ratios produced by <strong>logistic</strong>. First, let&rsquo;s define what is meant by a logit: A logit is defined as the log base e (log) of the odds. :</p><p style="margin-left: 30.0px;"><span>[1] logit(p) = log(odds) = log(p/q)</span></p><p style="margin-left: 30.0px;">The range is negative infinity to positive infinity. In regression it is easiest to model unbounded outcomes. <strong>Logistic regression is in reality an ordinary regression using the logit as the response variable</strong>. The logit transformation allows for a linear relationship between the response variable and the coefficients:</p><p style="margin-left: 30.0px;"><span>[2] logit(p) = a + bX</span></p><p style="margin-left: 30.0px;"><span>or</span></p><p style="margin-left: 30.0px;"><span>[3] log(p/q) = a + bX</span></p><p style="margin-left: 30.0px;">This means that the coefficients in a simple logistic regression are in terms of the log odds, that is, a coefficient of 1.694596 implies that a one unit change in gender results in a 1.694596 unit change in the log of the odds. Equation [3] can be expressed in odds by getting rid of the <span>log</span>. This is done by taking <span>e</span> to the power for both sides of the equation.</p><p style="margin-left: 30.0px;"><span>[4] e</span><sup>log(p/q)<sub> </sub></sup><span>= e<sup><span>a + bX</span></sup></span></p><p style="margin-left: 30.0px;"><span>or</span></p><p style="margin-left: 30.0px;"><span><span>[5]</span> p/q = e<sup><span>a + bX</span></sup></span></p><p style="margin-left: 30.0px;">From this, let us define the odds of being admitted for females and males separately:</p><p style="margin-left: 30.0px;"><span>[5a] odds<sub><span>female</span></sub> = p0 /q0</span></p><p style="margin-left: 30.0px;"><span>[5b] odds<sub><span>male</span></sub> = p1 /q1</span></p><p style="margin-left: 30.0px;">The <strong>odds ratio (OR)</strong> for gender is defined as the odds of being admitted for males over the odds of being admitted for females:</p><p style="margin-left: 30.0px;"><span>[6] OR = odds<sub><span>male</span></sub> /odds<sub><span>female</span></sub></span></p><p style="margin-left: 30.0px;">For this particular example (which can be generalized for all simple logistic regression models), the coefficient <em><strong>b</strong> </em>for a two category predictor can be defined as</p><p style="margin-left: 30.0px;"><span>[7a] b = log(odds<sub><span>male</span></sub>) &ndash; log(odds<sub><span>female</span></sub>) </span>= log(odds<sub><span style="letter-spacing: 0.0px;">male</span></sub> / odds<sub><span style="letter-spacing: 0.0px;">female</span></sub>)</p><p style="margin-left: 30.0px;">by the quotient rule of logarithms. Using the inverse property of the log function, you can exponentiate both sides of the equality [7a] to result in [6]:</p><p style="margin-left: 30.0px;"><span>[8] e<sup><span>b</span></sup> = e<sup><span>[log(odds<sub><span>male</span></sub>/odds<sub><span>female</span></sub>)]</span></sup> = <span>odds<sub><span>male</span></sub> /odds<sub><span>female</span></sub></span><sub> </sub>= OR</span></p><p style="margin-left: 30.0px;">which means the the exponentiated value of the coefficient <em><strong>b</strong> </em>results in the odds ratio for gender. In our particular example, e<sup><span>1.694596</span></sup> = 5.44 which implies that the odds of being admitted for males is 5.44 times that of females.</p><a name="Bookmark44"></a><h2 id="Bookmark44"><span class="nh-number">5.4. </span>Ordered Logistic Regression</h2><a name="Bookmark45"></a><h2 id="Bookmark45"><span class="nh-number">5.5. </span>Multinomial Logistic Regression</h2><a name="Bookmark46"></a><h1 id="Bookmark46"><span class="nh-number">6. </span><span style="letter-spacing: -0.01em;">Probability Distribution</span></h1><a name="Bookmark47"></a><h2 id="Bookmark47"><span class="nh-number">6.1. </span>Normal Distribution</h2><a name="Bookmark48"></a><h2 id="Bookmark48"><span class="nh-number">6.2. </span>Binomial Distribution</h2><ul><li><p><strong><span style="color: rgb(0,51,102);"><a class="external-link" href="https://en.wikipedia.org/wiki/Bernoulli_trial" rel="nofollow"><span style="color: rgb(0,51,102);">Binomial Experiment</span></a></span></strong></p></li></ul><p style="margin-left: 30.0px;"><span style="color: rgb(0,51,102);">A binomial experiment (or Bernoulli trial) is a statistical experiment that has the following properties:</span></p><ul style="margin-left: 20.0px;"><li>The experiment consists of n repeated trials.</li><li>The trials are independent.</li><li>The outcome of each trial is either <span>success</span> (s) or <span>failure</span> (f).</li></ul><ul><li>Expected value: <strong>np</strong></li><li>Variance: <strong>np(1-p)</strong></li></ul><p style="margin-left: 30.0px;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image" width="624" src="img_18.png" data-image-src="/download/attachments/1239118772/Img%207.png?version=1&amp;modificationDate=1578893723487&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1304552056" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Img 7.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="353" /></span></p><a name="Bookmark49"></a><h2 id="Bookmark49"><span class="nh-number">6.3. </span>Negative Binomial Distribution</h2><ul><li><strong>Negative Binomial Experiment</strong></li></ul><p style="margin-left: 30.0px;">A negative binomial experiment is a statistical experiment that has the following properties:</p><ul><li style="list-style-type: none;background-image: none;"><ul><li>The experiment consists of n repeated trials.</li><li>The trials are independent.</li><li>The outcome of each trial is either <span>success</span> (s) or <span>failure</span> (f).</li><li>p(s) is the same for every trial.</li><li>The experiment continues until x successes are observed.<br /><br /></li></ul></li></ul><p style="margin-left: 30.0px;">If X is the number of experiments until the x<sup>th</sup> success occurs, then X  is a discrete random variable called a <span>negative binomial</span>.</p><ul><li>Expected Value: <strong>x(1-p)/p</strong></li><li>Variance: <strong>x(1-p)/p^2</strong></li></ul><p style="margin-left: 60.0px;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image" width="624" src="img_19.png" data-image-src="/download/attachments/1239118772/Img%208.png?version=1&amp;modificationDate=1578894934050&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1304552092" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Img 8.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="282" /></span></p><a name="Bookmark50"></a><h2 id="Bookmark50"><span class="nh-number">6.4. </span>Geometric Distribution</h2><p style="margin-left: 30.0px;"><span style="color: rgb(0,0,0);">The geometric distribution is a special case of the negative binomial distribution that deals with the number of Bernoulli trials required to get a success (i.e., counting the number of failures before the first success).</span></p><p style="margin-left: 30.0px;"><span style="color: rgb(0,0,0);">The geometric distribution is a negative binomial distribution where the number of successes is 1. We express this with the following formula:</span></p><p style="margin-left: 30.0px;text-align: center;"><strong>g(n, p) = (1-p)<sup>(n-1)</sup>p</strong></p><ul><li style="text-align: left;">Expected<strong> </strong>Value: <strong>(1-p)/p</strong></li><li style="text-align: left;">Variance: <strong>(1-p)/p^2</strong></li></ul><a name="Bookmark51"></a><h2 id="Bookmark51"><span class="nh-number">6.5. </span>Poisson Distribution</h2><ul><li><strong>Poisson Experiment</strong></li></ul><p style="margin-left: 30.0px;">A <span>Poisson experiment</span> is a statistical experiment that has the following properties:</p><ul style="margin-left: 20.0px;"><li>The outcome of each trial is either <span>success</span> or <span>failure</span>.</li><li>The average number of successes &lambda; that occurs in a specified region is known.</li><li>The probability that a success will occur is proportional to the size of the region.</li><li>The probability that a success will occur in an extremely small region is virtually zero.</li></ul><p style="margin-left: 60.0px;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image" width="624" src="img_20.png" data-image-src="/download/attachments/1239118772/Img%209.png?version=1&amp;modificationDate=1578895772840&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1304552124" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Img 9.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="282" /></span></p><ul><li>Expected Value: <strong>&lambda;</strong></li><li>Variance: <strong>&lambda;</strong></li></ul><a name="Bookmark52"></a><h1 id="Bookmark52"><span class="nh-number">7. </span>Conditional Probabilities</h1><a name="Bookmark53"></a><h2 id="Bookmark53"><span class="nh-number">7.1. </span>Bayes' Theorem</h2><ul><li><span style="color: rgb(0,0,0);">p(A|B)*p(B) = p(A&amp;B) = p(B|A)*p(A)</span></li><li><span style="color: rgb(0,0,0);">p(A) = p(A&amp;B) + p(A&amp;^B)</span><span style="color: rgb(0,0,0);"><br /></span></li><li><span style="color: rgb(0,0,0);">1 = p(A|B) + <span style="color: rgb(0,0,0);">p(^A|B)</span></span></li></ul><a name="Bookmark54"></a><h2 id="Bookmark54"><span class="nh-number">7.2. </span><span>Na&iuml;ve Bayes</span></h2><p style="margin-left: 30.0px;"><span>What does the term '<strong>Naive</strong>' in 'Naive Bayes' mean ?</span></p><p style="margin-left: 60.0px;">The term '<strong>Naive</strong>' in Naive Bayes comes from the fact that the algorithm considers the features that it is using to make the predictions to be <strong>independent</strong> of each other, which may not always be the case.</p><p style="margin-left: 60.0px;"><br /></p><ul><li><span>Na&iuml;ve assumption:</span><ul><li><span>P(A &amp; B) = P(A)*P(B), A and B are independent</span></li></ul><span><span> </span></span></li><li><span>已知：</span><ul><li><span>P(A | x1, x2,&hellip;, xi) is the proportion of P(x1, x2, &hellip;, xi | A) * P(A) = P(x1 | A)*P(x2 | A)*&hellip;*P(xi | A) * P(A)</span></li><li><span>P(</span><span>B</span><span> | x1, x2,&hellip;, xi) is the proportion of P(x1, x2, &hellip;, xi | B) * P(B) = P(x1 | B)*P(x2 | B)*&hellip;*P(xi | B) * P(B)</span></li></ul></li><li><span>未知：</span><ul><li><span>P(x1, x2, xi)</span></li></ul></li><li><span>求</span><span> </span><span>P(A | x1, x2,&hellip;, xi)</span><span>？</span><span> </span><span>P(</span><span>B</span><span> | x1, x2,&hellip;, xi)</span><span>？</span><span>Normalize proportions</span><ul><li><span>P(A | x1, x2,&hellip;, xi) = P(x1 | A)*P(x2 | A)*&hellip;*P(xi | A) * P(A)</span><span> / (</span><span>P(x1 | A)*P(x2 | A)*&hellip;*P(xi | A) * P(A) + P(x1 | B)*P(x2 | B)*&hellip;*P(xi | B) * P(B))</span></li><li><span>P(</span><span>B</span><span> | x1, x2,&hellip;, xi) = P(x1 | B)*P(x2 | B)*&hellip;*P(xi | B) * P(B) / (P(x1 | A)*P(x2 | A)*&hellip;*P(xi | A) * P(A) + P(x1 | B)*P(x2 | B)*&hellip;*P(xi | B) * P(B))</span></li></ul></li></ul><p><span><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image" height="97" src="img_21.png" data-image-src="/download/attachments/1239118772/Untitled%20picture%208.png?version=1&amp;modificationDate=1578811332703&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1299668325" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Untitled picture 8.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" width="624" /></span><br /></span></p><p style="margin-left: 60.0px;"><br /></p><p><br /></p><a name="Bookmark55"></a><h1 id="Bookmark55"><span class="nh-number">8. </span>Model Evaluation Metrics</h1><a name="Bookmark56"></a><h2 id="Bookmark56"><span class="nh-number">8.1. </span>Classification metrics</h2><a name="Bookmark57"></a><h3 id="Bookmark57"><span class="nh-number">8.1.1. </span>Confusion matrix</h3><p><br /></p><div class="table-wrap"><table style="margin-left: 0.3333in;; font-size:1.0em" class="confluenceTable"><colgroup><col /><col /><col /></colgroup><tbody><tr><td class="confluenceTd" style="padding:0.5em"><p> </p></td><td class="confluenceTd" style="padding:0.5em"><p><strong>Actual Positive</strong></p></td><td class="confluenceTd" style="padding:0.5em"><p><strong>Actual Negative</strong></p></td></tr><tr><td class="confluenceTd" style="padding:0.5em"><p><strong>Predicted Positive</strong></p></td><td class="confluenceTd" style="padding:0.5em"><p>True Positive</p></td><td class="confluenceTd" style="padding:0.5em"><p>False Positive (Type I error)</p></td></tr><tr><td class="confluenceTd" style="padding:0.5em"><p><strong>Predicted Negative</strong></p></td><td class="confluenceTd" style="padding:0.5em"><p>False Negative (Type II error)</p></td><td class="confluenceTd" style="padding:0.5em"><p>True Negative</p></td></tr></tbody></table></div><p><br /></p><a name="Bookmark58"></a><h3 id="Bookmark58"><span class="nh-number">8.1.2. </span>Accuracy</h3><p><br /></p><p style="margin-left: 0.375in;">Measures how often the classifier makes the correct prediction. It&rsquo;s the ratio of the number of correct predictions to the total number of predictions (the number of test data points).</p><p style="margin-left: 0.375in;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image" width="500" src="img_22.png" data-image-src="/download/attachments/1239118772/Img%200.png?version=1&amp;modificationDate=1578885720260&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1304551752" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Img 0.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="223" /></span></p><a name="Bookmark59"></a><h3 id="Bookmark59"><span class="nh-number">8.1.3. </span>Precision</h3><p><br /></p><p style="margin-left: 0.375in;">Tells us what proportion of messages we classified as spam, actually were spam. It is a ratio of true positives to all positives, in other words it is the ratio of <strong>True Positives/(True Positives + False Positives)</strong></p><p style="margin-left: 0.375in;"><strong><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image" width="500" src="img_23.png" data-image-src="/download/attachments/1239118772/Img%201.png?version=1&amp;modificationDate=1578885995193&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1304551774" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Img 1.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="209" /></span><br /></strong></p><a name="Bookmark60"></a><h3 id="Bookmark60"><span class="nh-number">8.1.4. </span>Recall (Sensitivity)</h3><p><br /></p><p style="margin-left: 0.375in;">Tells us what proportion of messages that actually were spam were classified by us as spam. It is a ratio of true positives to all the words that were actually spam, in other words it is the ratio of <strong>True Positives/(True Positives + False Negatives)</strong></p><p style="margin-left: 0.375in;"><strong><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image" width="500" src="img_24.png" data-image-src="/download/attachments/1239118772/Img%202.png?version=1&amp;modificationDate=1578886120930&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1304551776" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Img 2.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="195" /></span><br /></strong></p><a name="Bookmark61"></a><h3 id="Bookmark61"><span class="nh-number">8.1.5. </span>Specificity</h3><p style="margin-left: 30.0px;">Tell us what proportion of messages that actually were not spam were correctly classified by us as not spam. It is a ratio of true negative to all the words that actually were not spam, in other words it is the ratio of <strong>True Negative/(True Negative + False Positive)</strong></p><p style="margin-left: 300.0px;text-align: left;"><strong>Specificity = TN/(TN+FP)</strong></p><a name="Bookmark62"></a><h3 id="Bookmark62"><span class="nh-number">8.1.6. </span>F1 score</h3><p style="margin-left: 0.375in;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image" height="27" src="img_25.png" data-image-src="/download/attachments/1239118772/Img%203.png?version=1&amp;modificationDate=1578886458910&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1304551787" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Img 3.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" width="504" /></span></p><p style="margin-left: 0.375in;"><br /></p><p style="margin-left: 0.375in;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image" height="249" src="img_26.png" data-image-src="/download/attachments/1239118772/Img%204.png?version=1&amp;modificationDate=1578886511817&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1304551788" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Img 4.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" width="498" /></span></p><a name="Bookmark63"></a><h3 id="Bookmark63"><span class="nh-number">8.1.7. </span>F<sub>&beta;</sub> score</h3><p style="margin-left: 60.0px;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image" width="400" src="img_27.png" data-image-src="/download/attachments/1239118772/Img%205.png?version=1&amp;modificationDate=1578886594600&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1304551789" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Img 5.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="131" /></span></p><p style="margin-left: 30.0px;"><br /></p><ul><li><span>If care more about </span><strong>precision</strong><span>, you should move <strong>&beta; closer to </strong></span><strong>0</strong><span>. </span></li><li><span>If care more about </span><strong>recall</strong><span>, you should move <strong>&beta; towards </strong></span><strong>&infin;</strong><span>.</span><span><br /></span></li></ul><p><span><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image" width="624" src="img_28.png" data-image-src="/download/attachments/1239118772/Img%206.png?version=1&amp;modificationDate=1578886862877&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1304551796" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Img 6.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="413" /></span><br /></span></p><a name="Bookmark64"></a><h3 id="Bookmark64"><span class="nh-number">8.1.8. </span>ROC (Receiver Operating Characteristic) curve</h3><ul><li>True Positive rate (<strong>Recall</strong> or <strong>Sensitivity</strong>) vs False Positive rate (<strong>1 - Specificity</strong>)</li></ul><p style="margin-left: 60.0px;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image" width="400" src="img_29.png" data-image-src="/download/attachments/1239118772/ROC_space-2.png?version=1&amp;modificationDate=1578887857207&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1304551813" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="ROC_space-2.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" height="400" /></span></p><a name="Bookmark65"></a><h2 id="Bookmark65"><span class="nh-number">8.2. </span>Regression metrics</h2><a name="Bookmark66"></a><h3 id="Bookmark66"><span class="nh-number">8.2.1. </span>Mean Absolute Error (MAE)</h3><a name="Bookmark67"></a><h3 id="Bookmark67"><span class="nh-number">8.2.2. </span>Mean Square Error (MSE)</h3><a name="Bookmark68"></a><h3 id="Bookmark68"><span class="nh-number">8.2.3. </span>Root Mean Square Error (RMSE)</h3><a name="Bookmark69"></a><h3 id="Bookmark69"><span class="nh-number">8.2.4. </span>R<sup>2</sup> score</h3><p style="margin-left: 30.0px;"><span>r<sup>2</sup> = 1 - (SE<sub>line</sub>/SE<sub>y</sub>) -- what % of total variation is described by the variation in x. it measures how much prediction error is eliminated when we use least-squares regression.</span></p><a name="Bookmark70"></a><h2 id="Bookmark70"><span class="nh-number">8.3. </span><span>Cross Validation</span></h2><p><br /></p></div>
</div>
</div>
<div class="columnLayout single" data-layout="single">
<div class="cell normal" data-type="normal">
<div class="innerCell">
<a name="Bookmark71"></a><h1 id="Bookmark71"><span class="nh-number">9. </span>Controlled Randomized Experiments</h1><ul><li>Randomization reduce the bias by equalizing other factors that have not be explicitly accounted for in the experimental design</li><li>Objects or individuals are randomly assigned (by chance) to an experimental group</li></ul><a name="Bookmark72"></a><h2 id="Bookmark72"><span class="nh-number">9.1. </span>Random Sampling Methods</h2><ul><li>Simple random sampling</li><li>Stratified sampling</li><li>Clustered sampling</li><li>Systematic random sampling</li></ul><a name="Bookmark73"></a><h2 id="Bookmark73"><span class="nh-number">9.2. </span>Randomized Experimental Assignment</h2><ul><li>Completely randomized design</li><li>Randomized block design<ul><li><span style="color: rgb(0,0,0);">In a block design, experimental subjects are first divided into homogeneous blocks before they are randomly assigned to a treatment group. Then, within each age level, individuals would be assigned to treatment groups using a completely randomized design.</span></li></ul></li><li>Matched pairs design<br /><br /></li></ul><p style="margin-left: 60.0px;"><span class="confluence-embedded-file-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image" height="249" src="img_30.png" data-image-src="/download/attachments/1239118772/Untitled%20picture%2011.png?version=1&amp;modificationDate=1578882348627&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="1304551654" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="Untitled picture 11.png" data-base-url="https://confluence.expedia.biz" data-linked-resource-content-type="image/png" data-linked-resource-container-id="1239118772" data-linked-resource-container-version="72" width="498" /></span></p><p style="margin-left: 30.0px;"><strong>Response bias</strong> occurs when people systematically give wrong answers.</p><p style="margin-left: 30.0px;"><strong>Experimentation design</strong>: <a class="external-link" href="http://www.stat.yale.edu/Courses/1997-98/101/expdes.htm" rel="nofollow">http://www.stat.yale.edu/Courses/1997-98/101/expdes.htm</a></p><a name="Bookmark74"></a><h2 id="Bookmark74"><span class="nh-number">9.3. </span>Necessary Ingredients for Running Controlled Experiments</h2><ol><li>There are experimental units that can be assigned to different variants (test groups) with no interference;</li><li>There are enough experimental units;</li><li>Key metrics, ideally an OEC (<strong>O</strong>verall <strong>E</strong>valuation <strong>C</strong>riterion), are agreed upon and can by practically evaluated;</li><li>Changes are easy to make.</li></ol><p><br /></p><p><br /></p><p><br /></p><p><br /></p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<script>
Split(['#sidebar', '#content'], {
    sizes: [15, 85],
    minSize: 100
});
</script>

</body>
</html>
